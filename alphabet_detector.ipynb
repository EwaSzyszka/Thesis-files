{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "alphabet_detector.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "yyH99jQ8OE7G",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "247b8609-8610-4565-f59e-42d85c0d6665"
      },
      "source": [
        "#Mounting to the google drive\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cD0jwYAbH2hZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c07a08f0-61ca-4f84-9ae6-f78de9e1e407"
      },
      "source": [
        "#Cloning the dataset from github\n",
        "#This is where the DATA comes from \n",
        "\n",
        "#! git clone https://github.com/EwaSzyszka/Sample_dataset.git\n",
        "\n",
        "! git clone  https://github.com/EwaSzyszka/Stillness"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'Stillness' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xKWZ32f3IAOx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9ce72489-a7f6-4023-dfa0-baa6790483ca"
      },
      "source": [
        "#Checking the location that we are at \n",
        "\n",
        "! ls"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "drive  gdrive  sample_data  Sample_dataset  Stillness\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ETSboMzGIFSa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "58d597a9-6b48-47cb-ab97-24103915712b"
      },
      "source": [
        "#Checking the working directory \n",
        "\n",
        "! pwd"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hpHGRngnIOYF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#now you can go to content --> Sample_dataset  --> a and you will find the files from the github \n",
        "\n",
        "#a = \"/content/Sample_dataset/A\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H5sNPDci9ZY3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f6f7b15f-0d17-4ca8-ce5a-66bde1347f04"
      },
      "source": [
        "#print(a)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/Sample_dataset/A\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rYQh6D6MSlAF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5V9N9lO5bsfE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#___________________ HERE BEGINS THE VGG MODEL ___________________"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Edied5YSbskT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.python.keras.models import Sequential\n",
        "from tensorflow.python.keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D\n",
        "from keras.models import load_model\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Conv2D, Flatten \n",
        "import keras\n",
        "\n",
        "#Model loading imports \n",
        "import json\n",
        "import numpy as np\n",
        "from keras import models\n",
        "from keras.models import model_from_json, load_model\n",
        "\n",
        "#Data procesing imports \n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "import random\n",
        "import pickle\n",
        "\n",
        "#Visualization imports \n",
        "import os\n",
        "import cv2\n",
        "import glob\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.pyplot import imshow\n",
        "from matplotlib import pyplot as plt\n",
        "from IPython.display import display\n",
        "%matplotlib inline"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZEUlyi7bdIzJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 920
        },
        "outputId": "d0f9fac3-d6b1-406b-d6a4-93c816a7db83"
      },
      "source": [
        "\n",
        "#_____ SETTING THE DATA PATH ______\n",
        "#DATADIR = \"/content/Sample_dataset/\"\n",
        "DATADIR = \"/content/Stillness/\"\n",
        "\n",
        "#_____ CATEGORIES OF CLASSES ______\n",
        "CATEGORIES = ['A','B']\n",
        "#This is the final list for stillness:\n",
        "#[\"A\", \"B\", \"C\", \"D\", \"E\",\"F\", \"G\", \"I\", \"K\" , \"L\", \"M\", \"N\" , \"O\", \"P\", \"R\", \"S\", \"T\" , \"U\" , \"W\", \"Y\" ]\n",
        "\n",
        "#_____ SETTING UP THE TRAINING DATA ______\n",
        "\n",
        "'''setting the size of the images to 50x50'''\n",
        "IMG_SIZE = 224\n",
        "\n",
        "training_data = []\n",
        "\n",
        "def create_training_data():\n",
        "    for category in CATEGORIES:\n",
        "        path = os.path.join(DATADIR, category)\n",
        "        '''One hot encoding'''\n",
        "        one_hot_target = np.zeros(len(CATEGORIES))\n",
        "        class_num = CATEGORIES.index(category)  \n",
        "        one_hot_target[class_num] = 1\n",
        "        \n",
        "        for img in os.listdir(path):\n",
        "            try:\n",
        "                '''resizing the images and attaching one hot encoded values'''\n",
        "                img_array = cv2.imread(os.path.join(path, img)) \n",
        "                new_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE),3)   #I added 3 here that was not there before \n",
        "                training_data.append([new_array,one_hot_target])  \n",
        "            except Exception as e:\n",
        "                pass\n",
        "\n",
        "create_training_data()\n",
        "\n",
        "#___ SHUFFLING THE DATA TO IMPROVE THE TRAINING QUALITY _____\n",
        "random.shuffle(training_data)\n",
        "\n",
        "#____PRINTING SAMPLE DATA_____\n",
        "for sample in training_data[:1]:\n",
        "    print(\"This is one hot encoded label: \\n\", sample[1])\n",
        "    print(\"This is np.array of an image: \\n\", sample[0])\n",
        "\n",
        "X = [] #feature set\n",
        "y = [] #labels\n",
        "\n",
        "for features, label in training_data:\n",
        "    X.append(features)\n",
        "    y.append(np.asarray(label)) #converting y to np array \n",
        "    \n",
        "X = np.array(X).reshape(-1,IMG_SIZE,IMG_SIZE, 3) # 1 because it is a gray scale\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "This is one hot encoded label: \n",
            " [1. 0.]\n",
            "This is np.array of an image: \n",
            " [[[125 132 132]\n",
            "  [125 132 131]\n",
            "  [125 131 133]\n",
            "  ...\n",
            "  [109 127 139]\n",
            "  [105 123 135]\n",
            "  [255   0   0]]\n",
            "\n",
            " [[123 132 134]\n",
            "  [127 133 135]\n",
            "  [126 132 134]\n",
            "  ...\n",
            "  [ 99 116 130]\n",
            "  [ 95 112 127]\n",
            "  [255   0   0]]\n",
            "\n",
            " [[124 133 137]\n",
            "  [123 129 131]\n",
            "  [126 133 135]\n",
            "  ...\n",
            "  [ 94 114 128]\n",
            "  [ 94 114 128]\n",
            "  [255   0   0]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[150 154 156]\n",
            "  [151 155 155]\n",
            "  [155 160 160]\n",
            "  ...\n",
            "  [246 244 253]\n",
            "  [226 224 233]\n",
            "  [255   0   0]]\n",
            "\n",
            " [[149 155 157]\n",
            "  [154 158 157]\n",
            "  [154 159 158]\n",
            "  ...\n",
            "  [234 232 242]\n",
            "  [231 230 239]\n",
            "  [255   0   0]]\n",
            "\n",
            " [[255   0   0]\n",
            "  [255   0   0]\n",
            "  [255   0   0]\n",
            "  ...\n",
            "  [255   0   0]\n",
            "  [255   0   0]\n",
            "  [255   0   0]]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GMn2PlnHA5GA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#____ NORMALIZING THE IMAGE DATA _____ \n",
        "X = X/255.0"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "enXVJHMZBEjz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9be8cb09-6128-4deb-b3c7-18486e148e96"
      },
      "source": [
        "#_____ PRINTING SHAPE OF X AND Y _____\n",
        "X = np.asarray(X)\n",
        "y = np.asarray(y)\n",
        "print(X.shape,y.shape)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(97, 224, 224, 3) (97, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vive60SXBIYp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#____ TEST-TRAIN SPLIT THE DATA _____ \n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qQGSnn3LBK94",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "57ac3f00-0375-4098-e64e-d94af7dbc561"
      },
      "source": [
        "#____ LENGTH OF THE TEST-TRAIN DATA_____\n",
        "\n",
        "print(\"\\n X train:\",len(X_train),\"\\n y train:\",len(y_train),\"\\n X test:\" ,len(X_test),\"\\n y test:\",len(y_test))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            " X train: 64 \n",
            " y train: 64 \n",
            " X test: 33 \n",
            " y test: 33\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kldXyFlyBN58",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#_____RESHAPING THE DATA ______ \n",
        "\n",
        "X_train = X_train.reshape(64,224,224,3)\n",
        "X_test = X_test.reshape(33,224,224,3)\n",
        "\n",
        "#X_train = X_train.reshape(64,50,50,3)\n",
        "#X_test = X_test.reshape(33,50,50,3)\n",
        "#X_train = X_train.reshape(589,50,50,3)\n",
        "#X_test = X_test.reshape(291,50,50,3)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WIKLB_7gBYlz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "34f8c4b4-9917-409e-d566-dd7136a5804c"
      },
      "source": [
        "#____ LENGTH OF THE TEST-TRAIN DATA AFTER RESHAPING____\n",
        "\n",
        "print(\"\\n X train:\",len(X_train),\"\\n y train:\",len(y_train),\"\\n X test:\" ,len(X_test),\"\\n y test:\",len(y_test))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            " X train: 64 \n",
            " y train: 64 \n",
            " X test: 33 \n",
            " y test: 33\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VUomn6vuBbw3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7e978f12-9e83-4076-d22d-f138d7654ebd"
      },
      "source": [
        "#_____ CONVERTING TO NP.ARRAY _____\n",
        "y_train = np.asarray(y_train)\n",
        "y_test = np.asarray(y_test)\n",
        "type(y_train)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "numpy.ndarray"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AYvB0DpaVzTu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0dc8d337-95c6-41f0-e7c0-b95b877fa903"
      },
      "source": [
        "print(X_train.shape,y_train.shape)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(64, 224, 224, 3) (64, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rE2UrQkBaRjj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e4d19705-53da-475c-cf3b-a6808186ce5c"
      },
      "source": [
        "print(y_train)"
      ],
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0. 1.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [0. 1.]\n",
            " [0. 1.]\n",
            " [1. 0.]\n",
            " [1. 0.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NJp_D6g8Zk-E",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "9fec101e-84cc-45c8-f523-103d0a0be58e"
      },
      "source": [
        "#TRIAL FROM A BRILLIANT TUTORIAL https://deeplizard.com/learn/video/oDHpqu52soI \n",
        "\n",
        "\n",
        "from __future__ import division, print_function\n",
        "\n",
        "import os, json\n",
        "from glob import glob\n",
        "import numpy as np\n",
        "from scipy import misc, ndimage\n",
        "from scipy.ndimage.interpolation import zoom\n",
        "\n",
        "from keras import backend as K\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.utils.data_utils import get_file\n",
        "from keras.models import Sequential\n",
        "from keras.layers.core import Flatten, Dense, Dropout, Lambda\n",
        "from keras.layers.convolutional import Convolution2D, MaxPooling2D, ZeroPadding2D\n",
        "from keras.layers.pooling import GlobalAveragePooling2D\n",
        "from keras.optimizers import SGD, RMSprop, Adam\n",
        "from keras.preprocessing import image\n",
        "import keras   \n",
        "import keras.applications.vgg16\n",
        "from  keras.layers import Input\n",
        "\n",
        "\n",
        "\n",
        "input_tensor = Input(shape=(224,224,3))\n",
        "VGG_model=keras.applications.vgg16.VGG16(weights='imagenet',include_top= True,input_tensor=input_tensor)\n",
        "\n",
        "VGG_model.summary()\n",
        "\n",
        "\n",
        "print(type(VGG_model))\n",
        "\n",
        "#Replicating the VGG 16 model again appart from the last Dense layer, which needs to be changed. By default there are 1000 categories to be detected \n",
        "#and I need to change it to the desired number of categories detected. \n",
        "model = Sequential()\n",
        "for layer in VGG_model.layers[:-1]:\n",
        "    model.add(layer)\n",
        "\n",
        "#you set this if the hands are included in the original imagenet category\n",
        "for layer in model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "#here you change the number of units to the number of categories that you need to recognise \n",
        "model.add(Dense(units=2, activation='softmax'))\n",
        "model.summary()\n",
        "\n",
        "model.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=3)\n",
        "#the last dense layer must contain the number of predictions\n",
        "\n",
        "\n",
        "#VGG_model.compile(loss='sparse_categorical_crossentropy', optimizer=tf.keras.optimizers.Adadelta(rho=0.9), metrics=['sparse_categorical_accuracy'])\n",
        "#VGG_model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=3)\n"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"vgg16\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_7 (InputLayer)         (None, 224, 224, 3)       0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 25088)             0         \n",
            "_________________________________________________________________\n",
            "fc1 (Dense)                  (None, 4096)              102764544 \n",
            "_________________________________________________________________\n",
            "fc2 (Dense)                  (None, 4096)              16781312  \n",
            "_________________________________________________________________\n",
            "predictions (Dense)          (None, 1000)              4097000   \n",
            "=================================================================\n",
            "Total params: 138,357,544\n",
            "Trainable params: 138,357,544\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "<class 'keras.engine.training.Model'>\n",
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 25088)             0         \n",
            "_________________________________________________________________\n",
            "fc1 (Dense)                  (None, 4096)              102764544 \n",
            "_________________________________________________________________\n",
            "fc2 (Dense)                  (None, 4096)              16781312  \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 2)                 8194      \n",
            "=================================================================\n",
            "Total params: 134,268,738\n",
            "Trainable params: 8,194\n",
            "Non-trainable params: 134,260,544\n",
            "_________________________________________________________________\n",
            "Train on 64 samples, validate on 33 samples\n",
            "Epoch 1/3\n",
            "64/64 [==============================] - 49s 772ms/step - loss: 0.7059 - accuracy: 0.5625 - val_loss: 0.6932 - val_accuracy: 0.4242\n",
            "Epoch 2/3\n",
            "64/64 [==============================] - 49s 761ms/step - loss: 0.7048 - accuracy: 0.5469 - val_loss: 0.7118 - val_accuracy: 0.6364\n",
            "Epoch 3/3\n",
            "64/64 [==============================] - 50s 787ms/step - loss: 0.7064 - accuracy: 0.5625 - val_loss: 0.6946 - val_accuracy: 0.6364\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.callbacks.History at 0x7f155cd16550>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1_pYdehVJGzt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 345
        },
        "outputId": "571707ea-2cb0-4ecd-be86-fe9a8fb39000"
      },
      "source": [
        "'''\n",
        "This is the correct VGG architecture. As I did not have an access to GPU to \n",
        "run the full model and the size of dataset was too big to train it on my computer's CPU\n",
        "I have created below a simplified VGG architecture. Below you can find the code for the \n",
        "VGG-16 implementation which can be run on a GPU, after the input image size would be \n",
        "changed into 224 x 224, as the VGG-16 paper suggests. \n",
        "'''\n",
        "#_______ VGG ________\n",
        "\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.layers.convolutional import Conv2D\n",
        "from keras.layers import Convolution2D as Conv2D\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers.convolutional import Deconv2D as Conv2DTranspose\n",
        "#from tensorflow.keras import backend as k\n",
        "#from tensorflow.keras.models import load_model\n",
        "#from tensorflow.keras.models import Sequential\n",
        "#from tensorflow.keras.layers import Conv2D\n",
        "#from tensorflow.keras.layers import MaxPooling2D\n",
        "#from tensorflow.python.keras.layers import Flatten, Dense\n",
        "from keras.optimizers import SGD\n",
        "from keras.optimizers import adam\n",
        "\n",
        "# Conv Block 1\n",
        "model.add(Conv2D(64, (3, 3), padding='same', activation='relu', input_shape=X_train.shape[1:], name='block1_conv1', data_format='channels_last'))\n",
        "model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
        "\n",
        "# Conv Block 2\n",
        "model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
        "model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
        "\n",
        "# Conv Block 3\n",
        "model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
        "model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
        "model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
        "\n",
        "# Conv Block 4\n",
        "model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
        "model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
        "model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
        "\n",
        "# Conv Block 5\n",
        "model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
        "model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
        "model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
        "\n",
        "# FC layers\n",
        "model.add(Flatten())\n",
        "model.add(Dense(4096, activation='relu'))\n",
        "model.add(Dense(4096, activation='relu'))\n",
        "model.add(Dense(1000, activation='softmax'))\n",
        "\n",
        "\n",
        "#model.compile(loss='categorical_crossentropy', optimizer= tf.keras.optimizers.SGD, metrics=['accuracy'])\n",
        "#model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=3)\n",
        "\n",
        "\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer=tf.keras.optimizers.Adadelta(rho=0.9), metrics=['accuracy'])\n",
        "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=3)\n"
      ],
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-108-c582ce083c78>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'categorical_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdadelta\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrho\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1152\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1153\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1154\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m   1155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1156\u001b[0m         \u001b[0;31m# Prepare validation data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m    619\u001b[0m                 \u001b[0mfeed_output_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    620\u001b[0m                 \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 621\u001b[0;31m                 exception_prefix='target')\n\u001b[0m\u001b[1;32m    622\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    623\u001b[0m             \u001b[0;31m# Generate sample-wise weight values given the `sample_weight` and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    143\u001b[0m                             \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m                             \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' but got array with shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m                             str(data_shape))\n\u001b[0m\u001b[1;32m    146\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Error when checking target: expected dense_6 to have shape (1000,) but got array with shape (2,)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Zwc-MU6U2A9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 234
        },
        "outputId": "d4faf007-4cf1-4233-919a-5d80fe49d089"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers.core import Flatten, Dense, Dropout\n",
        "from keras.layers.convolutional import Convolution2D, MaxPooling2D, ZeroPadding2D\n",
        "from keras.optimizers import SGD\n",
        "import cv2, numpy as np\n",
        "\n",
        "def VGG_16(weights_path=None):\n",
        "    model = Sequential()\n",
        "    model.add(ZeroPadding2D((1,1),input_shape=(3,224,224)))\n",
        "    model.add(Convolution2D(64, 3, 3, activation='relu'))\n",
        "    model.add(ZeroPadding2D((1,1)))\n",
        "    model.add(Convolution2D(64, 3, 3, activation='relu'))\n",
        "    model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
        "\n",
        "    model.add(ZeroPadding2D((1,1)))\n",
        "    model.add(Convolution2D(128, 3, 3, activation='relu'))\n",
        "    model.add(ZeroPadding2D((1,1)))\n",
        "    model.add(Convolution2D(128, 3, 3, activation='relu'))\n",
        "    model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
        "\n",
        "    model.add(ZeroPadding2D((1,1)))\n",
        "    model.add(Convolution2D(256, 3, 3, activation='relu'))\n",
        "    model.add(ZeroPadding2D((1,1)))\n",
        "    model.add(Convolution2D(256, 3, 3, activation='relu'))\n",
        "    model.add(ZeroPadding2D((1,1)))\n",
        "    model.add(Convolution2D(256, 3, 3, activation='relu'))\n",
        "    model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
        "\n",
        "    model.add(ZeroPadding2D((1,1)))\n",
        "    model.add(Convolution2D(512, 3, 3, activation='relu'))\n",
        "    model.add(ZeroPadding2D((1,1)))\n",
        "    model.add(Convolution2D(512, 3, 3, activation='relu'))\n",
        "    model.add(ZeroPadding2D((1,1)))\n",
        "    model.add(Convolution2D(512, 3, 3, activation='relu'))\n",
        "    model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
        "\n",
        "    model.add(ZeroPadding2D((1,1)))\n",
        "    model.add(Convolution2D(512, 3, 3, activation='relu'))\n",
        "    model.add(ZeroPadding2D((1,1)))\n",
        "    model.add(Convolution2D(512, 3, 3, activation='relu'))\n",
        "    model.add(ZeroPadding2D((1,1)))\n",
        "    model.add(Convolution2D(512, 3, 3, activation='relu'))\n",
        "    model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
        "\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(4096, activation='relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(4096, activation='relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(1000, activation='softmax'))\n",
        "\n",
        "    if weights_path:\n",
        "        model.load_weights(weights_path)\n",
        "\n",
        "    return model\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    im = cv2.resize(cv2.imread('cat.jpg'), (224, 224)).astype(np.float32)\n",
        "    im[:,:,0] -= 103.939\n",
        "    im[:,:,1] -= 116.779\n",
        "    im[:,:,2] -= 123.68\n",
        "    im = im.transpose((2,0,1))\n",
        "    im = np.expand_dims(im, axis=0)\n",
        "\n",
        "    # Test pretrained model\n",
        "    model = VGG_16('vgg16_weights.h5')\n",
        "    sgd = SGD(lr=0.1, decay=1e-6, momentum=0.9, nesterov=True)\n",
        "    model.compile(optimizer=sgd, loss='categorical_crossentropy')\n",
        "    out = model.predict(im)\n",
        "    print(np.argmax(out))"
      ],
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "error",
          "ename": "error",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-107-5379da0c919d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m     \u001b[0mim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cat.jpg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m224\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m224\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m     \u001b[0mim\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m103.939\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0mim\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m116.779\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31merror\u001b[0m: OpenCV(4.1.2) /io/opencv/modules/imgproc/src/resize.cpp:3720: error: (-215:Assertion failed) !ssize.empty() in function 'resize'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3V536KMkBeOu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "outputId": "ca00e44d-18fd-45b8-bbcb-b4395f4801a0"
      },
      "source": [
        "#________ SETTING UP THE SIMPLIFIED MODEL _______\n",
        "model = Sequential()\n",
        "model.add(Conv2D(64, kernel_size=3, activation=\"relu\", input_shape=(50,50,3)))\n",
        "model.add(Conv2D(32, kernel_size=3, activation=\"relu\"))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(2, activation=\"softmax\"))  #I have changed the number from 6 to 2 here \n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=3)"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 64 samples, validate on 33 samples\n",
            "Epoch 1/3\n",
            "64/64 [==============================] - 1s 16ms/step - loss: 0.8987 - accuracy: 0.6875 - val_loss: 0.9146 - val_accuracy: 0.4242\n",
            "Epoch 2/3\n",
            "64/64 [==============================] - 1s 10ms/step - loss: 0.6718 - accuracy: 0.6562 - val_loss: 0.5489 - val_accuracy: 0.6364\n",
            "Epoch 3/3\n",
            "64/64 [==============================] - 1s 10ms/step - loss: 0.4982 - accuracy: 0.6562 - val_loss: 0.4751 - val_accuracy: 0.7879\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.callbacks.History at 0x7f61459a2f60>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lz0L7TgQBo94",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "59c05b4d-e938-49e8-832b-7241dee1b99f"
      },
      "source": [
        "#How to assess the model: \n",
        "#Model loss and model accuracy \n",
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test loss: 0.6946404738859697\n",
            "Test accuracy: 0.6363636255264282\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f1IKUARlBr_-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "6bf66f1a-cf94-4bcd-f173-5ae6122dfb49"
      },
      "source": [
        "#________ MAKING A TEST PREDICTION _______\n",
        "\n",
        "first_predictions = model.predict(X_test[:4])\n",
        "\n",
        "'''Showing one hot encoded label that the prediction was made on '''\n",
        "print(y_test[0])\n",
        "\n",
        "\"\"\"Showing the image that the prediction was made on\"\"\"\n",
        "plt.imshow(Image.fromarray(X_test[0],'RGB'), interpolation='nearest')\n",
        "plt.axis(\"off\")\n",
        "plt.show()\n",
        "\n",
        "'''Showing was was actually predicted'''\n",
        "print(first_predictions[0])"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1. 0.]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "[0.4673105 0.5326895]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e9NL9AkgBu6i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#____ SAVINGS THE TRAINED MODEL ____ \n",
        "model.save('my_model.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eygP4v0HBx3L",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4fd81a28-cca6-443a-dd27-525c29991ef1"
      },
      "source": [
        "model_json = model.to_json()\n",
        "with open(\"model.json\", \"w\") as json_file:             \n",
        "     json_file.write(model_json) \n",
        "\n",
        "model.save_weights(\"model.h5\")\n",
        "print(\"Saved model to disk\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saved model to disk\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XWAQ-Fz1B2MZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#_______ LOADING THE TRAINED MODEL TO MAKE PREDICTIONS ON UNSEEN DATA ____\n",
        "model = models.load_model('my_model.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A6Lm4o9JB44_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#______ OBJECT OPENING TRAINED MODEL AND PREDICTING IMAGES FROM CAPTURED DATA_____\n",
        "\n",
        "class SignLanguageModel(object):\n",
        "\n",
        "    LETTER_LIST = [\"A\", \"B\", \"C\", \"D\", \"E\",\"F\"]\n",
        "\n",
        "    def __init__(self, model_json_file, model_weights_file):\n",
        "        # load model from JSON file\n",
        "        with open(model_json_file, \"r\") as json_file:\n",
        "            loaded_model_json = json_file.read()\n",
        "            self.loaded_model = model_from_json(loaded_model_json)\n",
        "\n",
        "        # load weights into the new model\n",
        "        self.loaded_model.load_weights(model_weights_file)\n",
        "        self.loaded_model._make_predict_function()\n",
        "\n",
        "    def predict_letter(self, img):\n",
        "        self.preds = self.loaded_model.predict(img)\n",
        "        print (self.preds)\n",
        "        return SignLanguageModel.LETTER_LIST[np.argmax(self.preds)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9P8wcPjNB9n9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#______ TIME TO CAPTURE DATA _____\n",
        "\n",
        "import cv2\n",
        "\n",
        "cam = cv2.VideoCapture(0)\n",
        "\n",
        "cv2.namedWindow(\"test\")\n",
        "\n",
        "img_counter = 0\n",
        "\n",
        "while True:\n",
        "    ret, frame = cam.read()\n",
        "    cv2.imshow(\"test\", frame)\n",
        "\n",
        "    \n",
        "    if not ret:\n",
        "        break\n",
        "    k = cv2.waitKey(1)\n",
        "\n",
        "    if k%256 == 27:\n",
        "        # ESC pressed\n",
        "        print(\"Escape hit, closing...\")\n",
        "        break\n",
        "    elif k%256 == 32:\n",
        "        # SPACE pressed\n",
        "        img_name = \"Desktop/Code/ImageRecognition/datacapture/opencv_frame_{}.png\".format(img_counter)\n",
        "        cv2.imwrite(img_name, frame)\n",
        "        print(\"{} written!\".format(img_name))\n",
        "        img_counter += 1\n",
        "\n",
        "cam.release()\n",
        "\n",
        "cv2.destroyAllWindows()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}